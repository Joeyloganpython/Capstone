{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2bdd7173-b9a7-4d1c-a32b-01753e22d3d9",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70c6ffd5-b9b7-4ca4-ac5d-69ad3f348191",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!python3 -m pip install -U matplotlib\n",
    "#!pip install -U scikit-learn\n",
    "#!pip install ipywidgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e8a12511-9c5a-4d43-89de-4b818b418ee1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enabling notebook extension jupyter-js-widgets/extension...\r\n",
      "      - Validating: \u001b[32mOK\u001b[0m\r\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from math import sqrt\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "from dateutil.relativedelta import relativedelta\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.multioutput import RegressorChain\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "%matplotlib inline\n",
    "from ipywidgets import interactive,widgets, interact, HBox, Layout,VBox\n",
    "!jupyter nbextension enable --py widgetsnbextension"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c621d8e1-6cf3-4b4b-b638-44f3789a925c",
   "metadata": {},
   "source": [
    "## Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff6de0e2-277e-4887-ae15-ef9ca87dbaf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install statsmodels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0963c961-1bf1-4f80-a21a-a112ab30c2b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Credit to Prof. Milad Toutounchian (Drexel University) for plotseasonal and seas_deco functions.\n",
    "    Those functions were taken from DSCI 631 - Applied Machine Learning Timeseries notebooks\n",
    "\"\"\"\n",
    "def plotseasonal(res, axes, suptitle):\n",
    "    res.observed.plot(ax=axes[0])\n",
    "    axes[0].set_ylabel('Observed', fontsize=12)\n",
    "    axes[0].set_title(suptitle, fontsize=12)\n",
    "    res.trend.plot(ax=axes[1])\n",
    "    axes[1].set_ylabel('Trend', fontsize=12)\n",
    "    res.seasonal.plot(ax=axes[2])\n",
    "    axes[2].set_ylabel('Seasonal', fontsize=12)\n",
    "    res.resid.plot(ax=axes[3])\n",
    "    axes[3].set_ylabel('Residual', fontsize=12)\n",
    "\n",
    "def seas_deco(df):\n",
    "    # Additive Decomposition\n",
    "    result_add = seasonal_decompose(df['Count'], model='additive', extrapolate_trend='freq')\n",
    "    \n",
    "    fig, axes = plt.subplots(ncols=2, nrows=4, sharex=True, figsize=(18,5))\n",
    "\n",
    "    plotseasonal(result_add, axes[:,0], 'Additive Decompose')\n",
    "    \n",
    "    \n",
    "    try:\n",
    "        # Multiplicative Decomposition \n",
    "        result_mul = seasonal_decompose(df['Count'], model='multiplicative', extrapolate_trend='freq')\n",
    "        plotseasonal(result_mul, axes[:,1], 'Multiplicative Decompose')\n",
    "    except ValueError:\n",
    "        print(\"Multiplicative Decompistion Error: Not Appropriate for zero or negative values\")\n",
    "    \n",
    "    plt.show()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2cd94752-fc10-402d-ae9c-2fe33c81347b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_timeseries_data(county = \"\"):\n",
    "    incidents_df = pd.read_csv('../data/Aggregated/incidents.csv')\n",
    "    \n",
    "    if county:\n",
    "        incidents_df = incidents_df[incidents_df['Incident County Name'] == county]\n",
    "    \n",
    "    incidents_df['Month'] = incidents_df['Incident Date'].apply(lambda x: pd.Timestamp(datetime.strptime(x,\"%m/%d/%Y\")).month)\n",
    "    \n",
    "#     incidents_df[\"Fentanyl\"] = incidents_df[\"All Drugs\"].apply(lambda x: 1 if \"FENTANYL\" in x else 0)\n",
    "    \n",
    "#     incidents_df[\"Heroin\"] = incidents_df[\"All Drugs\"].apply(lambda x: 1 if \"HEROIN\" in x else 0)\n",
    "    \n",
    "    incidents_df[\"Year\"] = incidents_df[\"Incident Date\"].apply(lambda x: datetime.strptime(x,\"%m/%d/%Y\").year)\n",
    "    \n",
    "    incidents_df['Count'] = 1\n",
    "\n",
    "    return incidents_df\n",
    "\n",
    "\n",
    "\"\"\"Credit to Marco Peixiero:\n",
    "https://towardsdatascience.com/the-complete-guide-to-time-series-forecasting-using-sklearn-pandas-and-numpy-7694c90e45c1\n",
    "\"\"\"\n",
    "def window_input_output(input_length: int, output_length: int, data: pd.DataFrame) -> pd.DataFrame:\n",
    "    \n",
    "    df = data.copy()\n",
    "    \n",
    "    # Create x-features\n",
    "    for i in range(1, input_length):\n",
    "        df[f'x_{i}'] = df['Count'].shift(-i)\n",
    "    \n",
    "    # Create y-targets\n",
    "    for i in range(output_length):\n",
    "        df[f'y_{i}'] = df['Count'].shift(-output_length-i)\n",
    "    \n",
    "    # Drop any rows with NaN to prevent errors \n",
    "    df = df.dropna(axis=0)\n",
    "    \n",
    "    return df\n",
    "\n",
    "def split_data(df, forecast = 5, test_size = 1, first_run = False):\n",
    "    \n",
    "    if first_run:\n",
    "        # Create lags \n",
    "        final_df = window_input_output(forecast, forecast, df)\n",
    "    else:\n",
    "        final_df = df\n",
    "        \n",
    "    # Extract features and targets\n",
    "    feature_cols = [col for col in final_df.columns if col.startswith('x') or col == \"Count\"]\n",
    "    target_cols = [col for col in final_df.columns if col.startswith('y')]\n",
    "    \n",
    "    # Split data according to test_size\n",
    "    x_train = final_df[feature_cols][:-test_size].values\n",
    "    y_train = final_df[target_cols][:-test_size].values\n",
    "\n",
    "    x_test = final_df[feature_cols][-test_size:].values\n",
    "    y_test = final_df[target_cols][-test_size:].values\n",
    "    \n",
    "    return x_train, x_test, y_train, y_test, final_df\n",
    "\n",
    "def fill_missing_months(df,\n",
    "                        start_year = 2018,\n",
    "                        end_year = 2022,\n",
    "                        start_month = 1,\n",
    "                        end_month = 12):\n",
    "    \n",
    "    # Ensure input has both month and year\n",
    "    if \"Year\" not in df.columns or \"Month\" not in df.columns:\n",
    "        raise ValueError(\"Missing one or more columns\")\n",
    "    \n",
    "    # Copy dataframe\n",
    "    temp_df = df.copy()\n",
    "    \n",
    "    # Find months that are missing in the set of dataframe\n",
    "    years = [i for i in range(start_year, end_year + 1)]\n",
    "    months = [i for i in range(start_month, end_month + 1)]\n",
    "    \n",
    "    # Complete Set of all combinations of years and months in the range required\n",
    "    combination_ls = set([y * 100 + m for y in years for m in months])\n",
    "    \n",
    "    # Set of months and years presented in the dataframe\n",
    "    a = set(temp_df[[\"Year\", \"Month\"]].apply(lambda x: x[\"Year\"] * 100 + x[\"Month\"], axis = 1).tolist())\n",
    "    \n",
    "    # Missing pieces\n",
    "    missing_months = combination_ls - a\n",
    "    \n",
    "    # Append missing months to dataframe\n",
    "    for period in missing_months:\n",
    "        month = period % 100\n",
    "        year = period // 100\n",
    "        county = temp_df[\"County\"].unique()[0]\n",
    "        temp_df = temp_df.append({'County': county,\n",
    "                                  'Year': year,\n",
    "                                  'Month': month,\n",
    "                                  'Count' : 0}, ignore_index = True)\n",
    "    \n",
    "    \n",
    "    return temp_df.sort_values(by = [\"Year\", \"Month\"])\n",
    "\n",
    "\n",
    "def df_with_timestamp(df):\n",
    "    \n",
    "    # Copy dataframe\n",
    "    temp_df = df.copy()\n",
    "    \n",
    "    # Convert year and month into datetime of the first day of the month\n",
    "    temp_df[\"Date\"] = temp_df.apply(lambda x: datetime(year = x[\"Year\"], month = x[\"Month\"], day = 1), axis = 1)\n",
    "    \n",
    "    # Return the new dataframe with date as index\n",
    "    return temp_df.set_index(\"Date\")\n",
    "\n",
    "\n",
    "def plot_forecast(orig_df,\n",
    "                  final_df,\n",
    "                  x_train,\n",
    "                  x_test,\n",
    "                  y_train,\n",
    "                  y_test,\n",
    "                  fitted_estimators = [],\n",
    "                  forecast = 5):\n",
    "    \n",
    "    ts_df = df_with_timestamp(orig_df[[\"Year\", \"Month\", \"Count\"]])\n",
    "    test_timestamp = [ts_df.index.tolist()[-forecast* 2 +1: -forecast], ts_df.index.tolist()[-forecast: ]]\n",
    "    \n",
    "    input_ts_ls = ts_df.iloc[:len(x_train) + 1,].index.tolist()\n",
    "    input_ts_ls.extend(test_timestamp[0])\n",
    "\n",
    "    input_count_ls = [i[0] for i in x_train]\n",
    "    input_count_ls.extend(x_test[0])\n",
    "    \n",
    "    # Plot data \n",
    "    fig, ax = plt.subplots(figsize=(10, 5))\n",
    "    ax.plot(input_ts_ls, input_count_ls, marker='P', color='blue', label='Input')\n",
    "    ax.plot(test_timestamp[1], y_test[0], marker='P', color='red', label='Actual')\n",
    "    \n",
    "    # Plot predicted values for each estimator\n",
    "    for est in fitted_estimators:\n",
    "        name = str(est.estimators_[0].__class__).split(\".\")[-1][:-2]\n",
    "        preds = est.predict(x_test)\n",
    "        ax.plot(test_timestamp[1], preds[0], marker='P', label=f'{name}')\n",
    "        print(f\"RMSE {name}: {sqrt(mean_squared_error(y_test, preds)):.2f}\")\n",
    "    \n",
    "    plt.legend()\n",
    "    \n",
    "    \n",
    "def append_row(df):\n",
    "    \n",
    "    # Create a copy of df and last row in df\n",
    "    temp_df = df.copy()\n",
    "    temp_row = temp_df.iloc[-1:, :].copy()\n",
    "    \n",
    "    # Shift all values to the left\n",
    "    for i in range(1,temp_row.shape[1]):\n",
    "        temp_row.iloc[0,i - 1] = temp_row.iloc[0,i]\n",
    "    \n",
    "    # Set last column to NaN (to be predicted)\n",
    "    temp_row.iloc[0, -1] = np.nan\n",
    "    \n",
    "    # Replace timestamp with the following month\n",
    "    temp_row = temp_row.rename(index={temp_row.index[0]: temp_row.index[0] + relativedelta(months = 1)})\n",
    "    \n",
    "    # Append new row to dataframe\n",
    "    temp_df = temp_df.append(temp_row)\n",
    "    \n",
    "    return temp_df\n",
    "\n",
    "def estim(est, **kwargs):\n",
    "    \n",
    "    # Default estimator if none exist\n",
    "    if not est:\n",
    "        rfr_seq =  GradientBoostingRegressor(loss = \"absolute_error\",\n",
    "                                            learning_rate = 0.1)\n",
    "        return RegressorChain(rfr_seq)\n",
    "    \n",
    "    # Initialize estimator according to the input and arguments\n",
    "    else:\n",
    "        if \"Random\" in est:\n",
    "            return RegressorChain(RandomForestRegressor(**kwargs))\n",
    "\n",
    "        if \"Decision\" in est:\n",
    "            kwargs_temp = {key:value for key,value in kwargs.items() if key != \"n_estimators\"}\n",
    "            return RegressorChain(DecisionTreeRegressor(**kwargs_temp))\n",
    "\n",
    "        if \"Gradient\" in est:\n",
    "            return RegressorChain(GradientBoostingRegressor(**kwargs))\n",
    "        else:\n",
    "            raise ValueError(\"Estimator not supported\")\n",
    "\n",
    "\n",
    "def pred_to_year(est,\n",
    "                 orig_df,\n",
    "                 year = 2024,\n",
    "                 month = 1,\n",
    "                 forecast = 5,\n",
    "                 test_size = 1,\n",
    "                 **kwargs):\n",
    "    \n",
    "    # Create data with lags, and split into train and test\n",
    "    (x_train,\n",
    "     x_test,\n",
    "     y_train,\n",
    "     y_test,\n",
    "     temp_df) = split_data(orig_df, forecast = forecast, test_size = test_size, first_run = True)\n",
    "    \n",
    "    # Convert indices to date timestamps\n",
    "    temp_df = df_with_timestamp(temp_df)\n",
    "    temp_df.drop([\"County\", \"Year\", \"Month\"], axis = 1, inplace = True)\n",
    "    \n",
    "    # Initialize helping variables\n",
    "    index = 0\n",
    "    last_train_index = len(temp_df) - 1 + forecast * 2\n",
    "    threshold = datetime(year = year, month = month, day = 1)\n",
    "    \n",
    "    # Iterate till threshold date is reached\n",
    "    while temp_df.iloc[-1:,:].index[0] < threshold:\n",
    "        \n",
    "        # Ensure not first run of the loop\n",
    "        if index != 0:\n",
    "            \n",
    "            # Append a new row with NaN in the last y-column (to be forecasted)\n",
    "            temp_df = append_row(temp_df)\n",
    "            \n",
    "            # Create data with lags, and split into train and test\n",
    "            (x_train,\n",
    "             x_test,\n",
    "             y_train,\n",
    "             y_test,\n",
    "             _) = split_data(temp_df, forecast = forecast, test_size = 1)\n",
    "            \n",
    "        # Initialize estimator\n",
    "        estimator = estim(est, **kwargs)\n",
    "        \n",
    "        # Fit & Predict\n",
    "        estimator.fit(x_train, y_train)\n",
    "        preds = estimator.predict(x_test)\n",
    "        \n",
    "        # Add the forecast to the last cell in dataframe\n",
    "        temp_df.iloc[-1, -1] = preds[0][-1]\n",
    "        \n",
    "        # Increase loop index\n",
    "        index += 1\n",
    "    \n",
    "    return temp_df, last_train_index\n",
    "\n",
    "def forecast_county(df,\n",
    "                    county = \"Philadelphia\",\n",
    "                    est = \"GradientBoostingRegressor\",\n",
    "                    forecast_size = 5,\n",
    "                    **kwargs):\n",
    "    \n",
    "    forecast_df, last_train_index = pred_to_year(est, orig_df = df[:-forecast_size], **kwargs)\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(10, 5))\n",
    "    print(f\"RMSE: {mean_squared_error(df.iloc[last_train_index:last_train_index + forecast_size]['Count'], forecast_df.iloc[last_train_index:last_train_index + forecast_size]['Count'])}\" )\n",
    "    plt.title(f\"Forecast for {county} to {kwargs['year'] if 'year' in kwargs.keys() else '2024'} using {est}\")    \n",
    "    \n",
    "    # Plot Input (Training set)\n",
    "    ax.plot(forecast_df.iloc[:last_train_index].index, forecast_df.iloc[:last_train_index][\"Count\"], marker='P', color='blue', label = \"Train\")\n",
    "    \n",
    "    # Plot Test set\n",
    "    ax.plot(forecast_df.iloc[last_train_index : last_train_index + 5].index, df.iloc[last_train_index : last_train_index + 5][\"Count\"], marker='P', color='red', label = \"Test\")\n",
    "    \n",
    "    # Plot forecast\n",
    "    ax.plot(forecast_df.iloc[last_train_index -1:last_train_index + 1].index, forecast_df.iloc[last_train_index -1 :last_train_index + 1][\"Count\"], '--', color='orange')\n",
    "    ax.plot(forecast_df.iloc[last_train_index:].index, forecast_df.iloc[last_train_index:][\"Count\"], marker='P', color='orange', label = \"Forecast\")\n",
    "    \n",
    "    # Show graph and legend\n",
    "    ax.legend()\n",
    "    plt.show()\n",
    "    \n",
    "    # Plot decomposition\n",
    "    seas_deco(forecast_df.iloc[:last_train_index])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1300233c-70df-48c0-a9be-ecc15bd36b4a",
   "metadata": {},
   "source": [
    "# Interactive Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3a7cdcee-0951-4630-81bd-6081fa268fc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading Dataset\n",
      "Preprocessing\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"Reading Dataset\")\n",
    "time_series_df = create_timeseries_data()\n",
    "ls = [\"Incident County Name\",\n",
    "  \"Month\",\n",
    "  \"Year\",\n",
    "  \"Count\"]\n",
    "\n",
    "print(\"Preprocessing\")\n",
    "time_series_df = time_series_df[ls]\n",
    "time_series_df = time_series_df.groupby(['Incident County Name',\n",
    "                                         'Year',\n",
    "                                         'Month']).sum().reset_index()\n",
    "time_series_df.rename(columns={'Incident County Name': 'County'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d166418a-82fe-4b14-bddb-4d8acfeff759",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create list of counties\n",
    "temp_df = pd.read_csv('../data/Aggregated/incidents.csv')\n",
    "counties_ls = temp_df[\"Incident County Name\"].unique().tolist()\n",
    "del temp_df\n",
    "\n",
    "# Create county dropdown\n",
    "county_dropdown = widgets.Dropdown(\n",
    "    options=counties_ls,\n",
    "    value='Philadelphia',\n",
    "    description='County:',\n",
    "    disabled=False,\n",
    ")\n",
    "\n",
    "# Create regressor dropdown\n",
    "regressor_dropdown = widgets.Dropdown(\n",
    "    options=[\"Gradient Boosting\", \"Random Forest\", \"Decision Tree\"],\n",
    "    value='Gradient Boosting',\n",
    "    description='Regressor:',\n",
    "    disabled=False,\n",
    ")\n",
    "\n",
    "# Month and Year sliders\n",
    "year_slider = widgets.IntSlider(\n",
    "    value=2024,\n",
    "    min=2023,\n",
    "    max=2026,\n",
    "    step=1,\n",
    "    description='Year:',\n",
    "    disabled=False,\n",
    "    continuous_update=False,\n",
    "    orientation='horizontal',\n",
    "    readout=True,\n",
    "    readout_format='d'\n",
    ")\n",
    "\n",
    "month_slider = widgets.IntSlider(\n",
    "    value=1,\n",
    "    min=1,\n",
    "    max=12,\n",
    "    step=1,\n",
    "    description='Month:',\n",
    "    disabled=False,\n",
    "    continuous_update=False,\n",
    "    orientation='horizontal',\n",
    "    readout=True,\n",
    "    readout_format='d'\n",
    ")\n",
    "\n",
    "\n",
    "# Hyper parameter tuning\n",
    "criterion_dropdown = widgets.Dropdown(\n",
    "    options=[\"friedman_mse\", \"squared_error\"],\n",
    "    value='friedman_mse',\n",
    "    description='Criterion:',\n",
    "    disabled=False,\n",
    ")\n",
    "\n",
    "max_features_dropdown = widgets.Dropdown(\n",
    "    options=[\"auto\", \"log2\", \"sqrt\"],\n",
    "    value='auto',\n",
    "    description='Max Features:',\n",
    "    disabled=False,\n",
    ")\n",
    "\n",
    "n_estimators_slider = widgets.IntSlider(\n",
    "    value=1,\n",
    "    min=2,\n",
    "    max=1000,\n",
    "    step=1,\n",
    "    description='N Estimators:',\n",
    "    disabled=False,\n",
    "    continuous_update=False,\n",
    "    orientation='horizontal',\n",
    "    readout=True,\n",
    "    readout_format='d'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a9abc4a3-15e7-4ace-8efb-5cfb00e824f3",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c4f90ffd9524b33b6a3d0df62ea86c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(Dropdown(description='County:', index=4, options=('Delaware', 'Chester', 'Beaverâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def f(county,\n",
    "      year,\n",
    "      regressor,\n",
    "      month,\n",
    "      criterion,\n",
    "      n_estimators,\n",
    "      max_features\n",
    "      ):\n",
    "    temp_df = time_series_df[time_series_df[\"County\"] == county]\n",
    "    temp_df = fill_missing_months(temp_df)\n",
    "    temp_df = temp_df[:-1] # Removing 2023\n",
    "    if \"Decision\" in regressor:\n",
    "        n_estimators_slider.disabled = True\n",
    "    else:\n",
    "        n_estimators_slider.disabled = False\n",
    "    forecast_county(temp_df,\n",
    "                    county = county,\n",
    "                    est = regressor,\n",
    "                    year = year,\n",
    "                    month = month,\n",
    "                    criterion = criterion,\n",
    "                    n_estimators = n_estimators,\n",
    "                    max_features = max_features,\n",
    "                    random_state = 42\n",
    "                   )\n",
    "\n",
    "interactive_plot = interactive(f,\n",
    "                               county = county_dropdown,\n",
    "                               regressor = regressor_dropdown,\n",
    "                               year = year_slider,\n",
    "                               month = month_slider,\n",
    "                               criterion = criterion_dropdown,\n",
    "                               n_estimators = n_estimators_slider,\n",
    "                               max_features = max_features_dropdown\n",
    "                               )\n",
    "\n",
    "controls = HBox(interactive_plot.children[:-1], layout = Layout(flex_flow='row wrap', width='85%'))\n",
    "output = interactive_plot.children[-1]\n",
    "display(VBox([controls, output]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95063e25-752d-485d-98d7-c5fa57d65723",
   "metadata": {},
   "source": [
    "# Testing Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8aeb22ba-ff2f-4bb5-91af-9735f57d91e5",
   "metadata": {},
   "source": [
    "### Reading Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8133daf-d1db-4abb-8f0e-ed415aa86f46",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_series_df = create_timeseries_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5604579d-234b-4bc2-b710-450b9812c5d9",
   "metadata": {},
   "source": [
    "### Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cef12072-33bf-4dbe-93d1-4f0e4919a21b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ls = [\"Incident County Name\",\n",
    "      \"Month\",\n",
    "      \"Year\",\n",
    "      \"Count\"]\n",
    "\n",
    "time_series_df = time_series_df[ls]\n",
    "time_series_df = time_series_df.groupby(['Incident County Name',\n",
    "                                         'Year',\n",
    "                                         'Month']).sum().reset_index()\n",
    "time_series_df.rename(columns={'Incident County Name': 'County'}, inplace=True)\n",
    "\n",
    "time_series_df = fill_missing_months(time_series_df)\n",
    "\n",
    "# Sanity Check\n",
    "# test[(test['County'] == 'Philadelphia')]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4d0b296-8cbb-4e2c-895b-772236c260ca",
   "metadata": {},
   "source": [
    "### Time Series Forecasting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16b1420d-8cfe-456e-928d-f573d184c60e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "forecast = 5\n",
    "test_size = 1\n",
    "(x_train,\n",
    " x_test,\n",
    " y_train,\n",
    " y_test,\n",
    " final_df) = split_data(time_series_df[:-1], forecast = forecast, test_size = test_size, first_run = True) # -1 is to remove Jan 2023"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1269de4-7728-4ca0-b18a-015c91f8fb43",
   "metadata": {},
   "source": [
    "### Decision Tree Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccf865f7-55b6-4f27-b845-78fa1700822a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dtr_seq = DecisionTreeRegressor(criterion = \"absolute_error\",\n",
    "                                max_depth = 1,\n",
    "                                random_state=42)\n",
    "chained_dtr = RegressorChain(dtr_seq)\n",
    "chained_dtr.fit(x_train, y_train)\n",
    "dtr_seq_preds = chained_dtr.predict(x_test)\n",
    "\n",
    "sqrt(mean_squared_error(y_test, dtr_seq_preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d11f028-158d-4f66-b33c-5ed5f9a757b7",
   "metadata": {},
   "source": [
    "### Random Forest Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d78999d7-0417-479c-b992-90836b69e162",
   "metadata": {},
   "outputs": [],
   "source": [
    "rfr_seq = RandomForestRegressor(criterion = \"friedman_mse\",\n",
    "                                max_depth = 1,\n",
    "                                random_state = 42)\n",
    "chained_rfr = RegressorChain(rfr_seq)\n",
    "chained_rfr.fit(x_train, y_train)\n",
    "rfr_seq_preds = chained_rfr.predict(x_test)\n",
    "\n",
    "sqrt(mean_squared_error(y_test, rfr_seq_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2051fd56-fcb5-4514-97c0-ed1a82385f19",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "gbr_seq = GradientBoostingRegressor(loss = \"absolute_error\",\n",
    "                                    learning_rate = 0.1,\n",
    "                                    random_state=42)\n",
    "chained_gbr = RegressorChain(gbr_seq)\n",
    "chained_gbr.fit(x_train, y_train)\n",
    "gbr_seq_preds = chained_gbr.predict(x_test)\n",
    "sqrt(mean_squared_error(y_test, gbr_seq_preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d395ab2-526a-47bd-9fa0-4abe86bd4b8a",
   "metadata": {},
   "source": [
    "### Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a7ca232-8e6a-4d13-a739-a1bdccd77f3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_forecast(orig_df = time_series_df[:-1],\n",
    "              final_df = final_df,\n",
    "              x_train = x_train,\n",
    "              x_test = x_test,\n",
    "              y_train = y_train,\n",
    "              y_test = y_test,\n",
    "              fitted_estimators = [chained_rfr,\n",
    "                                   chained_gbr,\n",
    "                                   chained_dtr])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99133ecb-c1e6-43ea-9890-adca038c0da2",
   "metadata": {},
   "source": [
    "### Prediction to 2024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf153076-0638-4e40-a8b4-ef2063c23603",
   "metadata": {},
   "outputs": [],
   "source": [
    "rfr_seq =  GradientBoostingRegressor(loss = \"absolute_error\",\n",
    "                                    learning_rate = 0.1)\n",
    "chained_rfr = RegressorChain(rfr_seq)\n",
    "\n",
    "_ = pred_to_year(LinearRegression(), time_series_df[:-1])\n",
    "_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfe91277-f5b0-4ab4-8467-793cef10b54f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "_ = pred_to_year(\"Gradient\", orig_df = time_series_df[:-1])\n",
    "_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ce831a5-60a4-45cb-a1e7-f0a97546be98",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10, 5))\n",
    "plt.title(\"Prediction to 2024 using Gradient Boosting Regression\")\n",
    "ax.plot(_.index, _[\"Count\"], marker='P', color='red')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "209bf20c-19e9-449f-a4f0-c8fe02cc3812",
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = pred_to_year(\"Random Forest\", criterion = \"friedman_mse\", n_estimators = 200, orig_df= time_series_df[:-1])\n",
    "fig, ax = plt.subplots(figsize=(10, 5))\n",
    "plt.title(\"Prediction to 2024 using Random Forest Regression\")\n",
    "ax.plot(_.index, _[\"Count\"], marker='P', color='blue',)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "179744ef-6003-4e2d-9ba1-7280760ceb0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = pred_to_year(\"Decision Forest\", criterion = \"friedman_mse\", max_features = \"log2\", orig_df= time_series_df[:-1])\n",
    "fig, ax = plt.subplots(figsize=(10, 5))\n",
    "plt.title(\"Prediction to 2024 using Decision Tree Regression\")\n",
    "ax.plot(_.index, _[\"Count\"], marker='P', color='blue',)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdcb2ca6-91d9-439d-8871-d0e9e3137149",
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = pred_to_year(\"Decision Forest\", criterion = \"friedman_mse\", max_features = \"log2\", orig_df= time_series_df[:-2])\n",
    "fig, ax = plt.subplots(figsize=(10, 5))\n",
    "plt.title(\"Prediction to 2024 using Decision Tree Regression\")\n",
    "ax.plot(_.index, _[\"Count\"], marker='P', color='blue',)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b5a3e06-86b2-4f36-9a79-194ba2530520",
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = pred_to_year(\"Gradient\", orig_df = time_series_df[:-10])\n",
    "fig, ax = plt.subplots(figsize=(10, 5))\n",
    "plt.title(\"Prediction to 2024 using Decision Tree Regression\")\n",
    "ax.plot(_.index, _[\"Count\"], marker='P', color='blue')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fc0dd76-d607-43b9-8fff-ffcc216defbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "forecast_county(county = \"Allegheny\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1448d534-6293-4c69-ad7e-4621348532a3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Capvenv",
   "language": "python",
   "name": "capvenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
